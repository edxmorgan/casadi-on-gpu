{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12455920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mr-robot/.local/lib/python3.12/site-packages/casadi_on_gpu.cpython-312-x86_64-linux-gnu.so\n",
      "dynamics_forward(sim_x_ptr: int, sim_u_ptr: int, sim_p_all_ptr: int, dt_ptr: int, f_ext_ptr: int, sim_x_next_all_ptr: int, n_candidates: int, threads_per_block: int = 128, stream_ptr: int = 0, sync: bool = True) -> None\n",
      "\n",
      "Launch dynamics kernel. Pointers (including dt_ptr) must be GPU addresses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import casadi_on_gpu as cog\n",
    "print(cog.__file__)\n",
    "print(cog.dynamics_forward.__doc__)\n",
    "import os, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7971b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mr-robot/sci_ws/casadi-on-gpu/src/posterior.bin\"\n",
    "param_dim = cog.DYNAMICS_PARAM_DIM\n",
    "\n",
    "# the file is float64, we cast to float32 for GPU.\n",
    "params = np.fromfile(path, dtype=np.float64).reshape(-1, param_dim).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cec930",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = params.shape[0]\n",
    "device = \"cuda\"\n",
    "sim_p_all = torch.from_numpy(params).to(device)\n",
    "sim_p_all = sim_p_all.contiguous()\n",
    "assert sim_p_all.is_cuda and sim_p_all.dtype == torch.float32\n",
    "assert torch.isfinite(sim_p_all).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d6d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0') tensor([0.1262, 0.2371, 0.3277, 0.4756, 0.5371, 0.6842, 0.5045, 0.7987, 0.8608,\n",
      "        0.7026, 1.9532, 1.3321], device='cuda:0')\n",
      "tensor([[ 0.1262,  0.2371,  0.3277,  ...,  0.7026,  1.9532,  1.3321],\n",
      "        [ 0.1263,  0.2387,  0.3274,  ..., -3.0556,  1.4371,  1.2419],\n",
      "        [ 0.1246,  0.2367,  0.3289,  ..., -0.3697,  2.4083,  1.1635],\n",
      "        ...,\n",
      "        [ 0.1259,  0.2366,  0.3277,  ..., -1.2767,  2.0363,  1.2118],\n",
      "        [ 0.1246,  0.2362,  0.3288,  ..., -0.3268,  2.8331,  1.2396],\n",
      "        [ 0.1269,  0.2373,  0.3270,  ..., -1.0844,  1.5446,  1.2502]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Same initial conditions as the C++ demo\n",
    "sim_x = torch.tensor([0.1 * (i + 1) for i in range(cog.DYNAMICS_STATE_DIM)],\n",
    "                    device=device, dtype=torch.float32)\n",
    "sim_u = torch.tensor([0.05 * (i + 1) for i in range(cog.DYNAMICS_CONTROL_DIM)],\n",
    "                    device=device, dtype=torch.float32)\n",
    "f_ext = torch.zeros((cog.DYNAMICS_CONTROL_DIM,), device=device, dtype=torch.float32)\n",
    "\n",
    "sim_x_next_all = torch.zeros((N, cog.DYNAMICS_OUT_DIM), device=device, dtype=torch.float32)\n",
    "\n",
    "dt = torch.tensor([0.04], device=device, dtype=torch.float32)\n",
    "stream = torch.cuda.current_stream().cuda_stream\n",
    "cog.dynamics_forward(\n",
    "    sim_x.data_ptr(),\n",
    "    sim_u.data_ptr(),\n",
    "    sim_p_all.data_ptr(),\n",
    "    dt.data_ptr(),\n",
    "    f_ext.data_ptr(),\n",
    "    sim_x_next_all.data_ptr(),\n",
    "    N,\n",
    "    threads_per_block=128,\n",
    "    stream_ptr=stream,\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "print(torch.isfinite(sim_x_next_all).all(), sim_x_next_all[0])\n",
    "print(sim_x_next_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ff5c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num bad rows: 27\n",
      "first bad rows: [5335, 14711, 14948, 20024, 23836, 26868, 27361, 30188, 30728, 31097, 32035, 32367, 33293, 34664, 38133, 38204, 41643, 49828, 54433, 55219, 56256, 57265, 58309, 59475, 71954, 76139, 77676]\n"
     ]
    }
   ],
   "source": [
    "bad_mask = ~torch.isfinite(sim_x_next_all)\n",
    "bad_rows = bad_mask.any(dim=1).nonzero().squeeze()\n",
    "\n",
    "print(\"num bad rows:\", bad_rows.numel())\n",
    "print(\"first bad rows:\", bad_rows.tolist())\n",
    "\n",
    "# bad rows are as a result of invalid combination of sim parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba67cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 parameter forward dynamics model with 12 states [Pytorch]\n",
      "Total: 1334.619 ms for 200 calls\n",
      "Per call: 6.6731 ms\n",
      "Throughput: 11,988,438 eval/s  (batch N=80000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# Warmup, avoid first call overhead\n",
    "warmup = 20\n",
    "reps = 200\n",
    "\n",
    "# Optional, lock GPU clocks can help on laptops, but skip if you do not want to change settings.\n",
    "\n",
    "# Warmup runs\n",
    "for _ in range(warmup):\n",
    "    cog.dynamics_forward(\n",
    "        sim_x.data_ptr(),\n",
    "        sim_u.data_ptr(),\n",
    "        sim_p_all.data_ptr(),\n",
    "        dt.data_ptr(),\n",
    "        f_ext.data_ptr(),\n",
    "        sim_x_next_all.data_ptr(),\n",
    "        N,\n",
    "        threads_per_block=128,\n",
    "        stream_ptr=torch.cuda.current_stream().cuda_stream,\n",
    "        sync=False,   # do not sync inside, we will sync around timing\n",
    "    )\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "for _ in range(reps):\n",
    "    cog.dynamics_forward(\n",
    "        sim_x.data_ptr(),\n",
    "        sim_u.data_ptr(),\n",
    "        sim_p_all.data_ptr(),\n",
    "        dt.data_ptr(),\n",
    "        f_ext.data_ptr(),\n",
    "        sim_x_next_all.data_ptr(),\n",
    "        N,\n",
    "        threads_per_block=128,\n",
    "        stream_ptr=torch.cuda.current_stream().cuda_stream,\n",
    "        sync=False,\n",
    "    )\n",
    "end.record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "ms = start.elapsed_time(end)\n",
    "ms_per_call = ms / reps\n",
    "evals_per_s = (N / ms_per_call) * 1000.0\n",
    "print(f\"33 parameter forward dynamics model with 12 states [Pytorch]\")\n",
    "print(f\"Total: {ms:.3f} ms for {reps} calls\")\n",
    "print(f\"Per call: {ms_per_call:.4f} ms\")\n",
    "print(f\"Throughput: {evals_per_s:,.0f} eval/s  (batch N={N})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81f71a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 parameter forward dynamics model with 12 states [CuPy]\n",
      "Total: 1330.460 ms for 200 calls\n",
      "Per call: 6.6523 ms\n",
      "Throughput: 12,025,920 eval/s (batch N=80000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import casadi_on_gpu as cog\n",
    "\n",
    "param_dim = cog.DYNAMICS_PARAM_DIM\n",
    "\n",
    "# Load parameters from file (float64 on disk), cast to float32, move to GPU\n",
    "params_cpu = np.fromfile(path, dtype=np.float64).reshape(-1, param_dim).astype(np.float32)\n",
    "sim_p_all = cp.asarray(params_cpu)\n",
    "\n",
    "# Choose how many to benchmark\n",
    "N = 80000\n",
    "sim_p_all = sim_p_all[:N, :]  # take first N rows\n",
    "sim_p_all = cp.ascontiguousarray(sim_p_all)\n",
    "\n",
    "# Inputs\n",
    "sim_x = cp.asarray([0.1 * (i + 1) for i in range(cog.DYNAMICS_STATE_DIM)], dtype=cp.float32)\n",
    "sim_u = cp.asarray([0.05 * (i + 1) for i in range(cog.DYNAMICS_CONTROL_DIM)], dtype=cp.float32)\n",
    "dt    = cp.asarray([0.04], dtype=cp.float32)\n",
    "f_ext = cp.zeros((cog.DYNAMICS_CONTROL_DIM,), dtype=cp.float32)\n",
    "\n",
    "# Output\n",
    "sim_x_next_all = cp.zeros((N, cog.DYNAMICS_OUT_DIM), dtype=cp.float32)\n",
    "\n",
    "stream = cp.cuda.get_current_stream().ptr\n",
    "\n",
    "# Warmup\n",
    "warmup = 20\n",
    "for _ in range(warmup):\n",
    "    cog.dynamics_forward(\n",
    "        sim_x.data.ptr,\n",
    "        sim_u.data.ptr,\n",
    "        sim_p_all.data.ptr,\n",
    "        dt.data.ptr,\n",
    "        f_ext.data.ptr,\n",
    "        sim_x_next_all.data.ptr,\n",
    "        N,\n",
    "        threads_per_block=128,\n",
    "        stream_ptr=stream,\n",
    "        sync=False,\n",
    "    )\n",
    "\n",
    "cp.cuda.runtime.deviceSynchronize()\n",
    "\n",
    "# Timing\n",
    "reps = 200\n",
    "start = cp.cuda.Event()\n",
    "end = cp.cuda.Event()\n",
    "\n",
    "start.record()\n",
    "for _ in range(reps):\n",
    "    cog.dynamics_forward(\n",
    "        sim_x.data.ptr,\n",
    "        sim_u.data.ptr,\n",
    "        sim_p_all.data.ptr,\n",
    "        dt.data.ptr,\n",
    "        f_ext.data.ptr,\n",
    "        sim_x_next_all.data.ptr,\n",
    "        N,\n",
    "        threads_per_block=128,\n",
    "        stream_ptr=stream,\n",
    "        sync=False,\n",
    "    )\n",
    "end.record()\n",
    "end.synchronize()\n",
    "\n",
    "ms = cp.cuda.get_elapsed_time(start, end)\n",
    "ms_per_call = ms / reps\n",
    "evals_per_s = (N / ms_per_call) * 1000.0\n",
    "\n",
    "print(\"33 parameter forward dynamics model with 12 states [CuPy]\")\n",
    "print(f\"Total: {ms:.3f} ms for {reps} calls\")\n",
    "print(f\"Per call: {ms_per_call:.4f} ms\")\n",
    "print(f\"Throughput: {evals_per_s:,.0f} eval/s (batch N={N})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3da0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
